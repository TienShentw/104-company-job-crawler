import re
import time
import requests
import pandas as pd
from datetime import datetime

# ============================
# å–å¾— company_id
# ============================
def get_company_id(url):

    # case 1ï¼šæœ¬ä¾†å°±æ˜¯å…¬å¸ç¶²å€
    if "/company/" in url:
        cid = url.split("/company/")[1].split("?")[0].split("#")[0]
        return cid

    # case 2ï¼šæ˜¯è·ç¼ºç¶²å€
    if "/job/" in url:
        jobNo = url.split("/job/")[1].split("?")[0].split("#")[0]

        api_url = f"https://www.104.com.tw/job/ajax/content/{jobNo}"

        headers = {
            "User-Agent": "Mozilla/5.0",
            "Referer": f"https://www.104.com.tw/job/{jobNo}"
        }

        res = requests.get(api_url, headers=headers)

        try:
            data = res.json()
        except Exception:
            print("âš  104 API è¢«æ“‹ï¼Œå¯èƒ½ç¼º Referer æˆ–è¢«å°ã€‚å›å‚³å…§å®¹ï¼š")
            print(res.text[:200])
            return None

        cust_url = data["data"]["header"]["custUrl"]
        cid = cust_url.split("/company/")[1]
        return cid

    raise ValueError("ç¶²å€ä¸æ˜¯ 104 å…¬å¸æˆ–è·ç¼ºé é¢")


# ============================
# list â†’ æ–‡å­—
# ============================
def list_to_text(lst):
    if not lst:
        return ""

    if isinstance(lst, list) and len(lst) > 0:
        # list of string
        if isinstance(lst[0], str):
            return "ã€".join(lst)

        # list of dict
        if isinstance(lst[0], dict):
            items = []
            for item in lst:
                if "code" in item and "ability" in item:
                    items.append(f"{item['code']}ï¼š{item['ability']}")
                else:
                    items.append("ã€".join([str(v) for v in item.values()]))
            return "ã€".join(items)

    return str(lst)


# ============================
# ä¸»è¦çˆ¬èŸ²åŠŸèƒ½
# ============================
def crawl_company_jobs(url, total_page):

    company_id = get_company_id(url)
    print("âœ” company_id =", company_id)

    headers = {
        "User-Agent": "Mozilla/5.0",
        "Referer": f"https://www.104.com.tw/company/{company_id}"
    }

    JobList = pd.DataFrame()

    for page_number in range(1, total_page + 1):

        list_url = f"https://www.104.com.tw/company/ajax/joblist/{company_id}?page={page_number}"
        print(f"\n=== æ­£åœ¨æŠ“å–ç¬¬ {page_number} é  ===")

        res = requests.get(list_url, headers=headers).json()

        jobs = res["data"]["list"]["normalJobs"]

        if not jobs:
            print("âš ï¸ ç„¡æ›´å¤šè·ç¼º")
            break

        for job in jobs:

            jobNo = job["encodedJobNo"]
            api_url = f"https://www.104.com.tw/job/ajax/content/{jobNo}"

            print("â†’ æ­£åœ¨çˆ¬å–ï¼š", api_url)

            try:
                job_json = requests.get(api_url, headers=headers).json()
                data = job_json["data"]

                header = data["header"]
                condition = data["condition"]
                jobdetail = data["jobDetail"]

                row = {
                    "å·¥ä½œè·ç¨±": header.get("jobName", ""),
                    "æ›´æ–°æ—¥æœŸ": header.get("appearDate", ""),
                    "å·¥ä½œå…§å®¹": jobdetail.get("jobDescription", ""),
                    "å·¥ä½œå¾…é‡": jobdetail.get("salary", ""),
                    "ä¸Šç­åœ°é»": jobdetail.get("addressRegion", "") + jobdetail.get("addressDetail", ""),

                    "è·å‹™é¡åˆ¥": jobdetail.get("jobCategory", [{}])[0].get("description", ""),

                    "ç®¡ç†è²¬ä»»": jobdetail.get("manageResp", ""),
                    "å‡ºå·®å¤–æ´¾": jobdetail.get("businessTrip", ""),
                    "ä¸Šç­æ™‚æ®µ": jobdetail.get("workPeriod", ""),
                    "ä¼‘å‡åˆ¶åº¦": jobdetail.get("vacationPolicy", ""),
                    "å¯ä¸Šç­æ—¥": jobdetail.get("startWorkingDay", ""),
                    "éœ€æ±‚äººæ•¸": jobdetail.get("needEmp", ""),

                    "å­¸æ­·è¦æ±‚": condition.get("edu", ""),
                    "å·¥ä½œç¶“æ­·": condition.get("workExp", ""),

                    "èªæ–‡æ¢ä»¶": list_to_text(condition.get("language", [])),
                    "æ“…é•·å·¥å…·": list_to_text(condition.get("specialty", [])),
                    "å·¥ä½œæŠ€èƒ½": list_to_text(condition.get("skill", [])),
                    "å…·å‚™è­‰ç…§": list_to_text(condition.get("certificate", [])),
                    "ç§‘ç³»è¦æ±‚": list_to_text(condition.get("major", [])),

                    "å…¶ä»–æ¢ä»¶": condition.get("other", ""),
                    "é€£çµè·¯å¾‘": f"https://www.104.com.tw/job/{jobNo}"
                }

                JobList = pd.concat([JobList, pd.DataFrame([row])], ignore_index=True)
                time.sleep(0.2)

            except Exception as e:
                print("âŒ éŒ¯èª¤ï¼š", e)
                time.sleep(1)
                continue

    print("\nğŸ‰ å®Œæˆï¼Œå…±æŠ“åˆ°", len(JobList), "ç­†è³‡æ–™ï¼")
    return JobList, company_id


# ============================
# ä¸»ç¨‹å¼å…¥å£
# ============================
if __name__ == "__main__":

    url = input("è«‹è²¼ä¸Š 104 å…¬å¸æˆ–è·ç¼ºç¶²å€ï¼š ").strip()
    total_page = int(input("è«‹è¼¸å…¥è¦çˆ¬å¹¾é ï¼š "))

    df, cid = crawl_company_jobs(url, total_page)

    # æ¸…å…¬å¸åï¼ˆç¬¬ä¸€æ¬¡è·ç¼ºçš„ headerï¼‰
    try:
        sample_job_url = f"https://www.104.com.tw/company/ajax/joblist/{cid}?page=1"
        sample = requests.get(sample_job_url, headers={"User-Agent": "Mozilla/5.0"}).json()
        first_job = sample["data"]["list"]["normalJobs"][0]
        jobNo = first_job["encodedJobNo"]

        detail = requests.get(
            f"https://www.104.com.tw/job/ajax/content/{jobNo}",
            headers={"User-Agent": "Mozilla/5.0"}
        ).json()

        company_name = detail["data"]["header"]["custName"]
        company_name = re.sub(r'[<>:"/\\|?*]', '', company_name)

    except:
        company_name = cid

    # å­˜æª”
    current_datetime = datetime.now()
    formatted_date = current_datetime.strftime("%Y-%m-%d-%H%M")

    output_name = f"JobList_{company_name}_{formatted_date}.xlsx"

    df.to_excel(output_name, index=False, encoding="utf-8")
    print(f"ğŸ“ æª”æ¡ˆå·²è¼¸å‡ºï¼š {output_name}")
